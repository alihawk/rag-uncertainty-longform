{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e220683",
   "metadata": {},
   "source": [
    "# Indexing BM25 on Wikipedia Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ee47b2",
   "metadata": {},
   "source": [
    "Source is Pyserini's own example:\n",
    "\n",
    "https://github.com/castorini/pyserini/blob/master/docs/usage-index.md#building-a-bm25-index-embeddable-python-implementation\n",
    "\n",
    "Steps omitted: extracting jsonl.gz first in my file system and afterwards with tar -xvf. (It has double compression, or I used the wrong decompression method) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eaec69",
   "metadata": {},
   "source": [
    "## 1. Indexing\n",
    "\n",
    "This uses DefaultLuceneDocumentGenerator which already by default features stopword removal and stemming\n",
    "\n",
    "- I have 14 threads, so I use half of them. More might be faster, but this seemed safe\n",
    "- \"--storePositions\" \"--storeDocvectors\" \"--storeRaw\" are expensive options but we need the raw documents for reranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d06d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "2025-11-12 13:43:02,659 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:208) - Setting log level to INFO\n",
      "2025-11-12 13:43:02,662 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:211) - ============ Loading Index Configuration ============\n",
      "2025-11-12 13:43:02,662 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:212) - AbstractIndexer settings:\n",
      "2025-11-12 13:43:02,670 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:213) -  + DocumentCollection path: data/data00/jiajie_jin/flashrag_indexes/wiki_dpr_100w\n",
      "2025-11-12 13:43:02,670 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:214) -  + CollectionClass: JsonCollection\n",
      "2025-11-12 13:43:02,671 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:215) -  + Index path: indexes/wiki_dump\n",
      "2025-11-12 13:43:02,671 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:216) -  + Threads: 7\n",
      "2025-11-12 13:43:02,671 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:217) -  + Optimize (merge segments)? false\n",
      "Nov 12, 2025 1:43:02 PM org.apache.lucene.store.MemorySegmentIndexInputProvider <init>\n",
      "INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false\n",
      "2025-11-12 13:43:02,693 INFO  [main] index.IndexCollection (IndexCollection.java:237) - Using DefaultEnglishAnalyzer\n",
      "2025-11-12 13:43:02,694 INFO  [main] index.IndexCollection (IndexCollection.java:238) - Stemmer: porter\n",
      "2025-11-12 13:43:02,694 INFO  [main] index.IndexCollection (IndexCollection.java:239) - Keep stopwords? false\n",
      "2025-11-12 13:43:02,694 INFO  [main] index.IndexCollection (IndexCollection.java:240) - Stopwords file: null\n",
      "2025-11-12 13:43:02,760 INFO  [main] index.IndexCollection (IndexCollection.java:188) - IndexCollection settings:\n",
      "2025-11-12 13:43:02,760 INFO  [main] index.IndexCollection (IndexCollection.java:189) -  + Generator: DefaultLuceneDocumentGenerator\n",
      "2025-11-12 13:43:02,760 INFO  [main] index.IndexCollection (IndexCollection.java:190) -  + Language: en\n",
      "2025-11-12 13:43:02,760 INFO  [main] index.IndexCollection (IndexCollection.java:191) -  + Stemmer: porter\n",
      "2025-11-12 13:43:02,760 INFO  [main] index.IndexCollection (IndexCollection.java:192) -  + Keep stopwords? false\n",
      "2025-11-12 13:43:02,761 INFO  [main] index.IndexCollection (IndexCollection.java:193) -  + Stopwords: null\n",
      "2025-11-12 13:43:02,761 INFO  [main] index.IndexCollection (IndexCollection.java:194) -  + Store positions? true\n",
      "2025-11-12 13:43:02,761 INFO  [main] index.IndexCollection (IndexCollection.java:195) -  + Store docvectors? true\n",
      "2025-11-12 13:43:02,761 INFO  [main] index.IndexCollection (IndexCollection.java:196) -  + Store document \"contents\" field? false\n",
      "2025-11-12 13:43:02,761 INFO  [main] index.IndexCollection (IndexCollection.java:197) -  + Store document \"raw\" field? true\n",
      "2025-11-12 13:43:02,761 INFO  [main] index.IndexCollection (IndexCollection.java:198) -  + Additional fields to index: []\n",
      "2025-11-12 13:43:02,761 INFO  [main] index.IndexCollection (IndexCollection.java:199) -  + Whitelist: null\n",
      "2025-11-12 13:43:02,761 INFO  [main] index.IndexCollection (IndexCollection.java:200) -  + Pretokenized?: false\n",
      "2025-11-12 13:43:02,761 INFO  [main] index.IndexCollection (IndexCollection.java:201) -  + Codec: Lucene99\n",
      "2025-11-12 13:43:02,761 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:241) - ============ Indexing Collection ============\n",
      "2025-11-12 13:43:02,763 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:250) - Thread pool with 7 threads initialized.\n",
      "2025-11-12 13:43:02,763 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:251) - 1 file found in data/data00/jiajie_jin/flashrag_indexes/wiki_dpr_100w\n",
      "2025-11-12 13:43:02,763 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:252) - Starting to index...\n",
      "2025-11-12 13:44:02,767 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 1,150,000 documents indexed\n",
      "2025-11-12 13:45:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 2,320,000 documents indexed\n",
      "2025-11-12 13:46:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 3,490,000 documents indexed\n",
      "2025-11-12 13:47:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 4,620,000 documents indexed\n",
      "2025-11-12 13:48:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 5,760,000 documents indexed\n",
      "2025-11-12 13:49:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 6,970,000 documents indexed\n",
      "2025-11-12 13:50:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 7,630,000 documents indexed\n",
      "2025-11-12 13:51:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 8,800,000 documents indexed\n",
      "2025-11-12 13:52:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 9,820,000 documents indexed\n",
      "2025-11-12 13:53:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 10,980,000 documents indexed\n",
      "2025-11-12 13:54:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 12,130,000 documents indexed\n",
      "2025-11-12 13:55:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 13,290,000 documents indexed\n",
      "2025-11-12 13:56:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 14,450,000 documents indexed\n",
      "2025-11-12 13:57:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 15,040,000 documents indexed\n",
      "2025-11-12 13:58:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 16,190,000 documents indexed\n",
      "2025-11-12 13:59:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 17,370,000 documents indexed\n",
      "2025-11-12 14:00:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 18,530,000 documents indexed\n",
      "2025-11-12 14:01:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 19,680,000 documents indexed\n",
      "2025-11-12 14:02:02,766 INFO  [pool-2-thread-1] index.IndexCollection (IndexCollection.java:292) - 20,850,000 documents indexed\n",
      "2025-11-12 14:02:34,352 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:292) - Indexing Complete! 21,015,324 documents indexed\n",
      "2025-11-12 14:02:34,352 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:293) - ============ Final Counter Values ============\n",
      "2025-11-12 14:02:34,352 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:294) - indexed:       21,015,324\n",
      "2025-11-12 14:02:34,352 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:295) - unindexable:            0\n",
      "2025-11-12 14:02:34,352 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:296) - empty:                  0\n",
      "2025-11-12 14:02:34,353 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:297) - skipped:                0\n",
      "2025-11-12 14:02:34,353 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:298) - errors:                 0\n",
      "2025-11-12 14:02:34,360 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:301) - Total 21,015,324 documents indexed in 00:19:31\n"
     ]
    }
   ],
   "source": [
    "# !python -m pyserini.index.lucene \\\n",
    "#   --collection JsonCollection \\\n",
    "#   --input data/data00/jiajie_jin/flashrag_indexes/wiki_dpr_100w \\\n",
    "#   --index indexes/wiki_dump \\\n",
    "#   --generator DefaultLuceneDocumentGenerator \\\n",
    "#   --threads 7 \\\n",
    "#   --storePositions --storeDocvectors --storeRaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849dc312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Nov 14, 2025 2:53:18 PM org.apache.lucene.store.MemorySegmentIndexInputProvider <init>\n",
      "INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\"Deaf basketball\"\\nDeaf basketball Deaf basketball is basketball played by deaf people. Sign language is used to communicate whistle blows and communication between players. The game played by deaf people is organized with national and international associations including Deaf Basketball Australia, Deaf Basketball UK and United States of America Deaf Basketball. Deaf basketball has gained great visibility because of athlete like Lance Allred who played basketball with the National Basketball Association\\'s (NBA) Cleveland Cavaliers. Allred is Hard of Hearing, with a 75-80% hearing loss wearing a hearing aid. He later on continued to play basketball professionally in the European basketball leagues. Another',\n",
       " '\"Deaf basketball\"\\ndeaf basketball. DIBF encourages the growth and development of deaf basketball in all nationals of the world through an organized program of education and instruction. The Federation schedules and conducts all international contests and championships in deaf basketball in cooperation with the Deaflympics (The Deaf Olympics) and its confederations. DIBF also maintains a documented history of the basketball by recording and reporting on all major international contests from the inception of international competitions to the present. Deaf basketball Deaf basketball is basketball played by deaf people. Sign language is used to communicate whistle blows and communication between players. The game']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyserini.search.lucene import LuceneSearcher\n",
    "import polars as pl\n",
    "import json\n",
    "\n",
    "query = 'Deaf Basketball'\n",
    "\n",
    "searcher = LuceneSearcher('index/wiki_dump')\n",
    "hits = searcher.search('Deaf Basketball',k=1000)\n",
    "\n",
    "docs = [json.loads(hits[i].lucene_document.get('raw'))[\"contents\"] for i in range(len(hits))]\n",
    "docs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a986e8ca",
   "metadata": {},
   "source": [
    "### Two variants (https://docs.langchain.com/oss/python/langchain/rag#rag-chains)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4831105b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Deaf basketball is a form of basketball specifically played by individuals who are deaf or hard of hearing. Communication on the court is facilitated through sign language for whistle blows and player coordination. Several countries actively participate in this sport, including:\n",
       "\n",
       "1. **Australia**: Deaf Basketball Australia organizes competitions and events.\n",
       "2. **United Kingdom (UK)**: Deaf Basketball UK manages local and national tournaments.\n",
       "3. **United States**: United States of America Deaf Basketball participates in various leagues and championships.\n",
       "4. **Finland**: Jussi Raisio, a notable deaf athlete, represented Finland at the International level.\n",
       "5. **Sweden**: Sweden has been actively involved through organizations like Kjell Gunna.\n",
       "6. **Lithuania**: Aleksas Jasiunas played a significant role in the formation of the Deaf International Basketball Federation (DIBF).\n",
       "7. **China and Ukraine**: These countries are also part of the DIBF, contributing to the global deaf basketball community.\n",
       "\n",
       "The Deaf International Basketball Federation (originally known as IDBA) was officially established to standardize rules and promote the sport internationally. This organization has played a crucial role in bringing together deaf athletes from various nations for competitions like the World Deaf Basketball Championships."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from IPython.display import display, Markdown\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "\n",
    "qwen = init_chat_model(model=\"ollama:qwen2.5:7B\").bind(logprobs=True)\n",
    "bm25 = LuceneSearcher('index/wiki_dump')\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L6-v2')\n",
    "query = \"what is deaf basketball and what countries have this?\"\n",
    "\n",
    "def get_top_3_rerank(query: str) -> str:\n",
    "    \"\"\"Using the user query, this function retrieves the three most relevant models using rerank\n",
    "\n",
    "    Args:\n",
    "        query (str): the user query\n",
    "\n",
    "    Returns:\n",
    "        str: a string containing the top three documents.\n",
    "    \"\"\"    \n",
    "    hits = bm25.search(query,k=1000)\n",
    "\n",
    "    docs = [json.loads(hits[i].lucene_document.get('raw'))[\"contents\"] for i in range(len(hits))]\n",
    "    \n",
    "\n",
    "    top_k = pl.DataFrame(cross_encoder.rank(query,docs,top_k=3,return_documents=True))\n",
    "    \n",
    "    return \"\\n\".join(top_k.get_column('text').to_list())\n",
    "\n",
    "agent = create_agent(\n",
    "    model=qwen,\n",
    "    tools=[get_top_3_rerank],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]}\n",
    ")\n",
    "display(Markdown(response[\"messages\"][-1].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5894f7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Deaf basketball refers to the sport of basketball played primarily by individuals who are deaf or hard of hearing. Communication during games relies heavily on sign language to convey whistle blows and other important game information between players, officials, and coaches.\n",
       "\n",
       "Several countries have active organizations and communities supporting deaf basketball:\n",
       "\n",
       "1. **United States**: The United States has a strong presence in deaf basketball through organizations like the USA Deaf Basketball (USADB).\n",
       "2. **Australia**: Deaf Basketball Australia organizes games and competitions for deaf players.\n",
       "3. **United Kingdom**: Deaf Basketball UK operates to support deaf athletes and organize local and national competitions.\n",
       "4. **Slovenia**: As mentioned, Slovenian player Miha Zupan has achieved high levels of professional play despite his hearing impairment.\n",
       "5. **Other countries** likely have similar organizations or groups that promote deaf basketball at the national level.\n",
       "\n",
       "These countries, along with others around the world, contribute to a vibrant and growing community of deaf athletes who compete in various tournaments and leagues dedicated to deaf sports. Additionally, there are international competitions like those organized by the Deaf International Basketball Federation (DIBF), which aligns with the broader Deaflympics movement to provide global visibility and opportunities for deaf athletes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "\n",
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"Creates a prompt where the retrieval context is concatenated to the prompt\n",
    "\n",
    "    Args:\n",
    "        request (ModelRequest): The full list of messages. From this the function retrieves the last human message\n",
    "\n",
    "    Returns:\n",
    "        str: a new prompt with context(top 3 rerank) that should \n",
    "    \"\"\"    \n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1]\n",
    "\n",
    "    retrieved_docs = get_top_3_rerank(last_query.content)\n",
    "\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. Use the following context in your response:\"\n",
    "        f\"\\n\\n{retrieved_docs}\"\n",
    "    )\n",
    "\n",
    "    return system_message\n",
    "\n",
    "\n",
    "agent = create_agent(qwen, tools=[], middleware=[prompt_with_context])\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]}\n",
    ")\n",
    "display(Markdown(response[\"messages\"][-1].content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a167e70b",
   "metadata": {},
   "source": [
    "### Using huggingface (for white-box :()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95eba4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Deaf basketball is a sport where deaf people play basketball using sign language instead of visual cues. It allows individuals who cannot hear to communicate through hand signals or vocalization. The sport has gained popularity due to the presence of a high-profile athlete named Lance Allred, who played basketball with the NBA Cleveland Cavaliers and won the league championship.\n",
       "\n",
       "Several countries have supported the development and growth of deaf basketball:\n",
       "1. Slovenia: Proving that deaf athletes can compete at the highest levels.\n",
       "2. Italy: Has produced a number of talented players.\n",
       "3. Canada: A country known for its strong deaf community and successful deaf basketball programs.\n",
       "4. South Africa: Known for their diverse population and dedication to deaf sports.\n",
       "5. Australia: Has seen a significant increase in deaf basketball participation over the past few years.\n",
       "6. Switzerland: Offers a supportive environment for deaf athletes and has produced many notable players.\n",
       "7. New Zealand: Known for its commitment to supporting deaf athletes and fostering deaf basketball culture globally.\n",
       "These nations recognize the importance of deaf basketball and work towards developing a global movement for deaf athletes and their organizations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Code mostly taken directly from huggingface: https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def prompt_with_context_from_string(query: str) -> str:\n",
    "    \"\"\"Creates a prompt where the retrieval context is concatenated to the prompt\n",
    "\n",
    "    Args:\n",
    "        str(query): The human query as string.\n",
    "\n",
    "    Returns:\n",
    "        str: a new prompt with context(top 3 rerank) that should \n",
    "    \"\"\"    \n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    retrieved_docs = get_top_3_rerank(query)\n",
    "\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. You answer in markdown. Use the following context in your response:\"\n",
    "        f\"\\n\\n{retrieved_docs}\"\n",
    "    )\n",
    "\n",
    "    return system_message\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": prompt_with_context_from_string(query)},\n",
    "    {\"role\": \"user\", \"content\": query}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=2048\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b55dd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-uncertainty-longform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
